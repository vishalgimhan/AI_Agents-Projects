{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJOSrRA2fudSL/yN71A/Mg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalgimhan/AI_Agents-Projects/blob/main/Multi_Agent_Research_Writer_DeepLearningAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Agents to Research and Write an Article"
      ],
      "metadata": {
        "id": "4O9kunkkkH7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HEtl-l3migmB",
        "outputId": "287931e5-7e0a-4928-8b8c-257f0825af59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting crewai==0.28.8\n",
            "  Downloading crewai-0.28.8-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting crewai_tools==0.1.6\n",
            "  Downloading crewai_tools-0.1.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langchain_community==0.0.29\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting appdirs<2.0.0,>=1.4.4 (from crewai==0.28.8)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (8.2.1)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.128-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting instructor<0.6.0,>=0.5.2 (from crewai==0.28.8)\n",
            "  Downloading instructor-0.5.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (1.81.0)\n",
            "Collecting opentelemetry-api<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_api-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from crewai==0.28.8)\n",
            "  Downloading opentelemetry_sdk-1.33.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from crewai==0.28.8) (2.11.4)\n",
            "Collecting python-dotenv==1.0.0 (from crewai==0.28.8)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting regex<2024.0.0,>=2023.12.25 (from crewai==0.28.8)\n",
            "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m884.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (4.13.4)\n",
            "Collecting chromadb<0.5.0,>=0.4.22 (from crewai_tools==0.1.6)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting lancedb<0.6.0,>=0.5.4 (from crewai_tools==0.1.6)\n",
            "  Downloading lancedb-0.5.7-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting pyright<2.0.0,>=1.1.350 (from crewai_tools==0.1.6)\n",
            "  Downloading pyright-1.1.401-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pytest<9.0.0,>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (8.3.5)\n",
            "Collecting pytube<16.0.0,>=15.0.0 (from crewai_tools==0.1.6)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai_tools==0.1.6) (2.32.3)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai_tools==0.1.6)\n",
            "  Downloading selenium-4.33.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community==0.0.29) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community==0.0.29)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain_community==0.0.29)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community==0.0.29)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1 (from langchain_community==0.0.29)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain_community==0.0.29)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.0.29) (1.20.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai_tools==0.1.6) (4.13.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.2.post1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading posthog-4.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading pulsar_client-3.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.71.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.15.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.10.18)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.127-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.125-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.124-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.93.1)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.122-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.121-py3-none-any.whl.metadata (9.3 kB)\n",
            "INFO: pip is still looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading embedchain-0.1.120-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.119-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.118-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.117-py3-none-any.whl.metadata (9.1 kB)\n",
            "  Downloading embedchain-0.1.116-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting clarifai<11.0.0,>=10.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai-10.11.1-py3-none-any.whl.metadata (22 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting embedchain<0.2.0,>=0.1.98 (from crewai==0.28.8)\n",
            "  Downloading embedchain-0.1.115-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading embedchain-0.1.114-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading embedchain-0.1.113-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (13.9.4)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "\u001b[33mWARNING: embedchain 0.1.128 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.128 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[33mWARNING: embedchain 0.1.127 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.127 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.126 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.125 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.124 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.123 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.122 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.121 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is still looking at multiple versions of embedchain[github,youtube] to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.120 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.119 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.118 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'github'\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: embedchain 0.1.117 does not provide the extra 'youtube'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting PyGithub<2.0.0,>=1.59.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading PyGithub-1.59.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: gitpython<4.0.0,>=3.1.38 in /usr/local/lib/python3.11/dist-packages (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.1.44)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting youtube-transcript-api<0.7.0,>=0.6.1 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading youtube_transcript_api-0.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting yt_dlp<2024.0.0,>=2023.11.14 (from embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl.metadata (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.7/160.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docstring-parser<0.16,>=0.15 (from instructor<0.6.0,>=0.5.2->crewai==0.28.8)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (5.5.2)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.11/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (18.1.0)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain<0.2.0,>=0.1.10 (from crewai==0.28.8)\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.10->crewai==0.28.8) (1.33)\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.10->crewai==0.28.8)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain_community==0.0.29)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.28.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.13.3->crewai==0.28.8) (1.3.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.33.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.33.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_proto-1.33.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.33.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->crewai==0.28.8) (5.29.4)\n",
            "Collecting opentelemetry-semantic-conventions==0.54b1 (from opentelemetry-sdk<2.0.0,>=1.22.0->crewai==0.28.8)\n",
            "  Downloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.4.2->crewai==0.28.8) (0.4.1)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai_tools==0.1.6)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai_tools==0.1.6) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai_tools==0.1.6) (2025.4.26)\n",
            "Collecting trio~=0.30.0 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community==0.0.29) (3.2.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.1.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.2.0)\n",
            "Collecting clarifai-grpc>=10.11.2 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_grpc-11.4.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_protocol-0.0.23-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting tritonclient>=2.34.0 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading tritonclient-2.58.0-py3-none-manylinux1_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: Pillow>=9.5.0 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (11.2.1)\n",
            "Collecting inquirerpy==0.3.4 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.9.0)\n",
            "Collecting fsspec==2024.6.1 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting click<9.0.0,>=8.1.7 (from crewai==0.28.8)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting contextlib2>=0.5.5 (from schema<0.8.0,>=0.7.5->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.51)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (1.17.2)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (4.0.12)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.24.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.26.1)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.33.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.16.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community==0.0.29) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api<2.0.0,>=1.22.0->crewai==0.28.8) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.10->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.9.0.post0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "INFO: pip is looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_cohere-0.1.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.7-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.5-py3-none-any.whl.metadata (6.4 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-util-http==0.54b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.10.1)\n",
            "Collecting pynacl>=1.4.0 (from PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai_tools==0.1.6)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (0.31.4)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (2.4.0)\n",
            "Collecting outcome (from trio~=0.30.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.0.29)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium<5.0.0,>=4.18.1->crewai_tools==0.1.6) (1.7.1)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (15.0.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api<0.7.0,>=0.6.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (0.7.1)\n",
            "Collecting mutagen (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.11/dist-packages (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (3.23.0)\n",
            "Collecting brotli (from yt_dlp<2024.0.0,>=2023.11.14->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "INFO: pip is looking at multiple versions of clarifai-protocol to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting clarifai-protocol>=0.0.14 (from clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading clarifai_protocol-0.0.22-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.21-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.19-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading clarifai_protocol-0.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading types_requests-2.32.0.20250602-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.38->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (5.0.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.71.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (2.7.2)\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading google_cloud_bigquery-3.34.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "  Downloading google_cloud_bigquery-3.31.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "  Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (1.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (3.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.1.2)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (1.17.1)\n",
            "Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.34.0->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8)\n",
            "  Downloading python_rapidjson-1.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.22->crewai_tools==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub<2.0.0,>=1.59.1->embedchain[github,youtube]<0.2.0,>=0.1.85->crewai_tools==0.1.6) (2.22)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai<11.0.0,>=10.0.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.2.13)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.98->crewai==0.28.8) (0.6.1)\n",
            "Downloading crewai-0.28.8-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.1.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading embedchain-0.1.113-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-0.5.2-py3-none-any.whl (33 kB)\n",
            "Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.33.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.33.1-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.33.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.33.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.33.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.54b1-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.401-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m828.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.33.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clarifai-10.11.1-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.1.5-py3-none-any.whl (30 kB)\n",
            "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.33.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.54b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.54b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.54b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.54b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyGithub-1.59.1-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading youtube_transcript_api-0.6.3-py3-none-any.whl (622 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading clarifai_grpc-11.4.1-py3-none-any.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clarifai_protocol-0.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (370 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.9/247.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tritonclient-2.58.0-py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Downloading python_rapidjson-1.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250602-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=a4af53de1f11a5280a83940cb77606a988954518048a0ec11b9dac543084aa2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: ratelimiter, pypika, monotonic, durationpy, brotli, appdirs, wsproto, uvloop, types-requests, tenacity, semver, regex, pytube, python-rapidjson, python-dotenv, pysbd, pypdf, py, pulsar-client, pfzy, packaging, overrides, outcome, opentelemetry-util-http, opentelemetry-proto, numpy, nodeenv, mypy-extensions, mutagen, mmh3, importlib-metadata, humanfriendly, httpx-sse, httptools, fsspec, fastavro, docstring-parser, deprecated, contextlib2, click, bcrypt, backoff, asgiref, yt_dlp, youtube-transcript-api, watchfiles, uvicorn, typing-inspect, typer, tritonclient, trio, tiktoken, starlette, schema, retry, pyright, pynacl, pylance, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, marshmallow, inquirerpy, gptcache, deprecation, coloredlogs, clarifai-grpc, chroma-hnswlib, alembic, trio-websocket, opentelemetry-semantic-conventions, onnxruntime, langsmith, lancedb, kubernetes, fastapi, dataclasses-json, selenium, PyGithub, opentelemetry-sdk, opentelemetry-instrumentation, langchain-core, instructor, cohere, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain_community, langchain-cohere, google-cloud-bigquery, opentelemetry-instrumentation-fastapi, langchain, chromadb, clarifai-protocol, clarifai, embedchain, crewai_tools, crewai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.11.6\n",
            "    Uninstalling regex-2024.11.6:\n",
            "      Successfully uninstalled regex-2024.11.6\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: docstring-parser\n",
            "    Found existing installation: docstring_parser 0.16\n",
            "    Uninstalling docstring_parser-0.16:\n",
            "      Successfully uninstalled docstring_parser-0.16\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.2.1\n",
            "    Uninstalling click-8.2.1:\n",
            "      Successfully uninstalled click-8.2.1\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.3\n",
            "    Uninstalling typer-0.15.3:\n",
            "      Successfully uninstalled typer-0.15.3\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.9.0\n",
            "    Uninstalling tiktoken-0.9.0:\n",
            "      Successfully uninstalled tiktoken-0.9.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.42\n",
            "    Uninstalling langsmith-0.3.42:\n",
            "      Successfully uninstalled langsmith-0.3.42\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.60\n",
            "    Uninstalling langchain-core-0.3.60:\n",
            "      Successfully uninstalled langchain-core-0.3.60\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.8\n",
            "    Uninstalling langchain-text-splitters-0.3.8:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.8\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 3.33.0\n",
            "    Uninstalling google-cloud-bigquery-3.33.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-3.33.0\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.6.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "bigframes 2.4.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.30.0 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyGithub-1.59.1 alembic-1.16.1 appdirs-1.4.4 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 brotli-1.1.0 chroma-hnswlib-0.7.3 chromadb-0.4.24 clarifai-10.11.1 clarifai-grpc-11.4.1 clarifai-protocol-0.0.14 click-8.1.7 cohere-5.15.0 coloredlogs-15.0.1 contextlib2-21.6.0 crewai-0.28.8 crewai_tools-0.1.6 dataclasses-json-0.6.7 deprecated-1.2.18 deprecation-2.1.0 docstring-parser-0.15 durationpy-0.10 embedchain-0.1.113 fastapi-0.115.12 fastavro-1.11.1 fsspec-2024.6.1 google-cloud-bigquery-3.30.0 gptcache-0.1.44 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 importlib-metadata-8.6.1 inquirerpy-0.3.4 instructor-0.5.2 kubernetes-32.0.1 lancedb-0.5.7 langchain-0.1.13 langchain-cohere-0.1.5 langchain-core-0.1.53 langchain-openai-0.1.7 langchain-text-splitters-0.0.2 langchain_community-0.0.29 langsmith-0.1.147 marshmallow-3.26.1 mmh3-5.1.0 monotonic-1.6 mutagen-1.47.0 mypy-extensions-1.1.0 nodeenv-1.9.1 numpy-1.26.4 onnxruntime-1.22.0 opentelemetry-api-1.33.1 opentelemetry-exporter-otlp-proto-common-1.33.1 opentelemetry-exporter-otlp-proto-grpc-1.33.1 opentelemetry-exporter-otlp-proto-http-1.33.1 opentelemetry-instrumentation-0.54b1 opentelemetry-instrumentation-asgi-0.54b1 opentelemetry-instrumentation-fastapi-0.54b1 opentelemetry-proto-1.33.1 opentelemetry-sdk-1.33.1 opentelemetry-semantic-conventions-0.54b1 opentelemetry-util-http-0.54b1 outcome-1.3.0.post0 overrides-7.7.0 packaging-23.2 pfzy-0.3.4 posthog-3.25.0 pulsar-client-3.7.0 py-1.11.0 pylance-0.9.18 pynacl-1.5.0 pypdf-4.3.1 pypika-0.48.9 pyright-1.1.401 pysbd-0.3.4 python-dotenv-1.0.0 python-rapidjson-1.20 pytube-15.0.0 ratelimiter-1.2.0.post0 regex-2023.12.25 retry-0.9.2 schema-0.7.5 selenium-4.33.0 semver-3.0.4 starlette-0.46.2 tenacity-8.5.0 tiktoken-0.7.0 trio-0.30.0 trio-websocket-0.12.2 tritonclient-2.58.0 typer-0.9.4 types-requests-2.32.0.20250602 typing-inspect-0.9.0 uvicorn-0.34.3 uvloop-0.21.0 watchfiles-1.0.5 wsproto-1.2.0 youtube-transcript-api-0.6.3 yt_dlp-2023.12.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "importlib_metadata"
                ]
              },
              "id": "4d38fe956e01452ba9f729dbc53e8cca"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ui85r_7ih3rV"
      },
      "outputs": [],
      "source": [
        "# Warning Control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew"
      ],
      "metadata": {
        "id": "bfTIj1pjibcU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If using OpenAI models"
      ],
      "metadata": {
        "id": "gU1Lpd9xkpwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3NgdrFbHL6r",
        "outputId": "526f8705-17ff-4b23-9e44-e85305bc594a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: utils\n",
            "  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13906 sha256=d7b051c8a33eb90a1812ec2a030738e1c9c75639705815abd33482ec30ba4d3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/0c/b3/674aea8c5d91c642c817d4d630bd58faa316724b136844094d\n",
            "Successfully built utils\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from utils import get_openai_api_key\n",
        "\n",
        "# openai_api_key = get_openai_api_key()\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ],
      "metadata": {
        "id": "cArUBEdDifRu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mistral API"
      ],
      "metadata": {
        "id": "M4lZA1Qxkr_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENAI_API_KEY=your-mistral-api-key\n",
        "# OPENAI_API_BASE=https://api.mistral.ai/v1\n",
        "# OPENAI_MODEL_NAME=\"mistral-small\""
      ],
      "metadata": {
        "id": "badNKqiokrYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cohere"
      ],
      "metadata": {
        "id": "I8y9oSh2kzW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.chat_models import ChatCohere\n",
        "# # Initialize language model\n",
        "# os.environ[\"COHERE_API_KEY\"] = \"your-cohere-api-key\"\n",
        "# llm = ChatCohere()\n",
        "\n",
        "# ### you will pass \"llm\" to your agent function"
      ],
      "metadata": {
        "id": "d2mJjhJrkzzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face"
      ],
      "metadata": {
        "id": "OpJ5Z6q9k8kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_community.llms import HuggingFaceHub\n",
        "\n",
        "# llm = HuggingFaceHub(repo_id=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "#                      huggingfacehub_api_token=\"<HF_TOKEN_HERE>\",\n",
        "#                      task=\"text-generation\",\n",
        "# )\n",
        "\n",
        "# ### you will pass \"llm\" to your agent function"
      ],
      "metadata": {
        "id": "nXj1ffDBk5cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Groq"
      ],
      "metadata": {
        "id": "HJdLDXmFJrx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# llm = openai.OpenAI(\n",
        "#     base_url=\"https://api.groq.com/openai/v1\",\n",
        "#     api_key=os.environ.get(\"GROQ_API_KEY\")\n",
        "# )\n",
        "\n",
        "# in colab\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"llama3-8b-8192\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=userdata.get(\"GROQ_API_KEY\"),\n",
        ")"
      ],
      "metadata": {
        "id": "tdU3xw0TJsas"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Agents\n",
        "\n",
        "- Define your Agents, and provide them a `role`, `goal` and `backstory`.\n",
        "- It has been seen that LLMs perform better when they are role playing."
      ],
      "metadata": {
        "id": "9g-CfEDbMNOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: The benefit of using _multiple strings_ :\n",
        "```Python\n",
        "varname = \"line 1 of text\"\n",
        "          \"line 2 of text\"\n",
        "```\n",
        "\n",
        "versus the _triple quote docstring_:\n",
        "```Python\n",
        "varname = \"\"\"line 1 of text\n",
        "             line 2 of text\n",
        "          \"\"\"\n",
        "```\n",
        "is that it can avoid adding those whitespaces and newline characters, making it better formatted to be passed to the LLM."
      ],
      "metadata": {
        "id": "1tkQrg0qMlBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent: Planner"
      ],
      "metadata": {
        "id": "UWti9F4tMppa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "planner = Agent(\n",
        "    role=\"Content Planner\",\n",
        "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
        "    backstory=\"You're working on planning a blog article \"\n",
        "              \"about the topic: {topic}.\"\n",
        "              \"You collect information that helps the \"\n",
        "              \"audience learn something \"\n",
        "              \"and make informed decisions. \"\n",
        "              \"Your work is the basis for \"\n",
        "              \"the Content Writer to write an article on this topic.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "39jaMm_pMvIH"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent: Writer"
      ],
      "metadata": {
        "id": "xBxJ3pPsPWGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "writer = Agent(\n",
        "    role=\"Content Writer\",\n",
        "    goal=\"Write insightful and factually accuracte \"\n",
        "          \"opinion piece about the topic: {topic}\",\n",
        "    backstory=\"You're working on a writing \"\n",
        "              \"a new opinion piece about the topic: {topic}. \"\n",
        "              \"You base your writing on the work of \"\n",
        "              \"the Content Planner, who provides an outline \"\n",
        "              \"and relevant context about the topic. \"\n",
        "              \"You follow the main objectives and \"\n",
        "              \"direction of the outline, \"\n",
        "              \"as provide by the Content Planner. \"\n",
        "              \"You also provide objective and impartial insights \"\n",
        "              \"and back them up with information \"\n",
        "              \"provide by the Content Planner. \"\n",
        "              \"You acknowledge in your opinion piece \"\n",
        "              \"when your statements are opinions \"\n",
        "              \"as opposed to objective statements.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "_zb2jJiFKJV4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent: Editor"
      ],
      "metadata": {
        "id": "WG1yO4EBQiTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "editor = Agent(\n",
        "    role=\"Editor\",\n",
        "    goal=\"Edit a given blog post to align with \"\n",
        "         \"the writing style of the organization. \",\n",
        "    backstory=\"You are an editor who receives a blog post \"\n",
        "              \"from the Content Writer. \"\n",
        "              \"Your goal is to review the blog post \"\n",
        "              \"to ensure that it follows journalistic best practices,\"\n",
        "              \"provides balanced viewpoints \"\n",
        "              \"when providing opinions or assertions, \"\n",
        "              \"and also avoids major controversial topics \"\n",
        "              \"or opinions when possible.\",\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "cTIGm7-PQDyE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Tasks\n",
        "- Define your tasks, and provide them a `description`, `expected_output` and `agent`.*italicized text*"
      ],
      "metadata": {
        "id": "cY4yhVg7Q40l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task: Plan"
      ],
      "metadata": {
        "id": "hPmR1zH-RJUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plan = Task(\n",
        "    description=(\n",
        "        \"1. Prioritize the latest trends, key players, \"\n",
        "            \"and noteworthy news on {topic}.\\n\"\n",
        "        \"2. Identify the target audience, considering \"\n",
        "            \"their interests and pain points.\\n\"\n",
        "        \"3. Develop a detailed content outline including \"\n",
        "            \"an introduction, key points, and a call to action.\\n\"\n",
        "        \"4. Include SEO keywords and relevant data or sources.\"\n",
        "    ),\n",
        "    expected_output=\"A comprehensive content plan document \"\n",
        "        \"with an outline, audience analysis, \"\n",
        "        \"SEO keywords, and resources.\",\n",
        "    agent=planner,\n",
        ")"
      ],
      "metadata": {
        "id": "i97pAkvzQmDO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task: Write"
      ],
      "metadata": {
        "id": "6nMUwKdeRb8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write = Task(\n",
        "    description=(\n",
        "        \"1. Use the content plan to craft a compelling \"\n",
        "            \"blog post on {topic}.\\n\"\n",
        "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
        "\t\t\"3. Sections/Subtitles are properly named \"\n",
        "            \"in an engaging manner.\\n\"\n",
        "        \"4. Ensure the post is structured with an \"\n",
        "            \"engaging introduction, insightful body, \"\n",
        "            \"and a summarizing conclusion.\\n\"\n",
        "        \"5. Proofread for grammatical errors and \"\n",
        "            \"alignment with the brand's voice.\\n\"\n",
        "    ),\n",
        "    expected_output=\"A well-written blog post \"\n",
        "        \"in markdown format, ready for publication, \"\n",
        "        \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=writer,\n",
        ")"
      ],
      "metadata": {
        "id": "V1QHa0B3RaGp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task: Edit"
      ],
      "metadata": {
        "id": "_R1kO3ucTGJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edit = Task(\n",
        "    description=(\"Proofread the given blog post for \"\n",
        "                 \"grammatical errors and \"\n",
        "                 \"alignment with the brand's voice.\"),\n",
        "    expected_output=\"A well-written blog post in markdown format, \"\n",
        "                    \"ready for publication, \"\n",
        "                    \"each section should have 2 or 3 paragraphs.\",\n",
        "    agent=editor\n",
        ")"
      ],
      "metadata": {
        "id": "jxOSbfIwRg-s"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Crew\n",
        "\n",
        "- Create your crew of Agents\n",
        "- Pass the tasks to be performed by those agents.\n",
        "    - **Note**: *For this simple example*, the tasks will be performed sequentially (i.e they are dependent on each other), so the _order_ of the task in the list _matters_.\n",
        "- `verbose=2` allows you to see all the logs of the execution."
      ],
      "metadata": {
        "id": "QJd5RIWdTbzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crew = Crew(\n",
        "    agents=[planner, writer, editor],\n",
        "    tasks=[plan, write, edit],\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHhn42IiTTmL",
        "outputId": "a903f8b8-8b26-4bde-96b8-2b3a5d270b5e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Crew"
      ],
      "metadata": {
        "id": "9muy80edTr-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = crew.kickoff(inputs={\"topic\": \"Artifiical Intelligence\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYe7V4iDTnXx",
        "outputId": "443bbd3a-0273-4f02-f3ce-40b42cee471c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Planner\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Prioritize the latest trends, key players, and noteworthy news on Artifiical Intelligence.\n",
            "2. Identify the target audience, considering their interests and pain points.\n",
            "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
            "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "**Content Plan: Artificial Intelligence**\n",
            "\n",
            "**I. Introduction**\n",
            "\n",
            "* Title: \"Unlocking the Power of Artificial Intelligence: Trends, Players, and Future Prospects\"\n",
            "* Subtitle: \"Understanding the latest developments and innovations in AI\"\n",
            "* Keywords: Artificial Intelligence, AI, Machine Learning, Deep Learning, Natural Language Processing\n",
            "* Meta Description: \"Explore the latest trends, key players, and noteworthy news in Artificial Intelligence, and discover the potential applications and future prospects of this rapidly evolving field.\"\n",
            "* Resource: \"AI for Everyone\" by Andrew Ng (Book)\n",
            "\n",
            "**II. Audience Analysis**\n",
            "\n",
            "* Target Audience: Technology enthusiasts, professionals in the field of computer science and engineering, entrepreneurs and innovators, and students interested in AI\n",
            "* Interests:\n",
            "\t+ Latest developments and breakthroughs in AI\n",
            "\t+ Real-world applications and case studies of AI\n",
            "\t+ Future prospects and potential risks of AI\n",
            "\t+ Insights from industry leaders and experts\n",
            "* Pain Points:\n",
            "\t+ Difficulty in understanding complex AI concepts\n",
            "\t+ Limited knowledge of AI applications and potential uses\n",
            "\t+ Concerns about the impact of AI on employment and society\n",
            "\n",
            "**III. Content Outline**\n",
            "\n",
            "I. Introduction\n",
            "\n",
            "* Brief overview of AI and its history\n",
            "* Importance of AI in modern society and technology\n",
            "\n",
            "II. Latest Trends in AI\n",
            "\n",
            "* Machine Learning and Deep Learning\n",
            "* Natural Language Processing and Speech Recognition\n",
            "* Computer Vision and Image Recognition\n",
            "* Robotics and Automation\n",
            "\n",
            "III. Key Players in AI\n",
            "\n",
            "* Google's AlphaGo and DeepMind\n",
            "* Facebook's AI Lab and OpenWorm\n",
            "* Amazon's Alexa and SageMaker\n",
            "* Microsoft's Azure Machine Learning and Cognitive Services\n",
            "\n",
            "IV. Noteworthy News and Developments\n",
            "\n",
            "* Recent breakthroughs in AI research and applications\n",
            "* Industry announcements and partnerships\n",
            "* Government initiatives and regulations\n",
            "\n",
            "V. Future Prospects and Challenges\n",
            "\n",
            "* Potential applications and uses of AI\n",
            "* Challenges and limitations of AI development\n",
            "* Ethical considerations and potential risks\n",
            "\n",
            "VI. Conclusion\n",
            "\n",
            "* Recap of key points and trends\n",
            "* Call to action for readers to explore AI further\n",
            "\n",
            "**IV. SEO Keywords and Relevant Data/ Sources**\n",
            "\n",
            "* Keywords: Artificial Intelligence, AI, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Automation\n",
            "* Sources:\n",
            "\t+ \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (Book)\n",
            "\t+ \"AI for Everyone\" by Andrew Ng (Book)\n",
            "\t+ \"The AI Revolution\" by Kai-Fu Lee (Book)\n",
            "\t+ \"AI and Machine Learning\" by Stanford University (Online Course)\n",
            "\t+ \"AI Trends\" by CB Insights (Report)\n",
            "\n",
            "**V. Call to Action**\n",
            "\n",
            "* Encourage readers to explore AI further and stay updated on the latest developments and trends\n",
            "* Provide resources and links to relevant articles, courses, and books\n",
            "* Invite readers to share their thoughts and experiences with AI\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Content Planner] Task output: **Content Plan: Artificial Intelligence**\n",
            "\n",
            "**I. Introduction**\n",
            "\n",
            "* Title: \"Unlocking the Power of Artificial Intelligence: Trends, Players, and Future Prospects\"\n",
            "* Subtitle: \"Understanding the latest developments and innovations in AI\"\n",
            "* Keywords: Artificial Intelligence, AI, Machine Learning, Deep Learning, Natural Language Processing\n",
            "* Meta Description: \"Explore the latest trends, key players, and noteworthy news in Artificial Intelligence, and discover the potential applications and future prospects of this rapidly evolving field.\"\n",
            "* Resource: \"AI for Everyone\" by Andrew Ng (Book)\n",
            "\n",
            "**II. Audience Analysis**\n",
            "\n",
            "* Target Audience: Technology enthusiasts, professionals in the field of computer science and engineering, entrepreneurs and innovators, and students interested in AI\n",
            "* Interests:\n",
            "\t+ Latest developments and breakthroughs in AI\n",
            "\t+ Real-world applications and case studies of AI\n",
            "\t+ Future prospects and potential risks of AI\n",
            "\t+ Insights from industry leaders and experts\n",
            "* Pain Points:\n",
            "\t+ Difficulty in understanding complex AI concepts\n",
            "\t+ Limited knowledge of AI applications and potential uses\n",
            "\t+ Concerns about the impact of AI on employment and society\n",
            "\n",
            "**III. Content Outline**\n",
            "\n",
            "I. Introduction\n",
            "\n",
            "* Brief overview of AI and its history\n",
            "* Importance of AI in modern society and technology\n",
            "\n",
            "II. Latest Trends in AI\n",
            "\n",
            "* Machine Learning and Deep Learning\n",
            "* Natural Language Processing and Speech Recognition\n",
            "* Computer Vision and Image Recognition\n",
            "* Robotics and Automation\n",
            "\n",
            "III. Key Players in AI\n",
            "\n",
            "* Google's AlphaGo and DeepMind\n",
            "* Facebook's AI Lab and OpenWorm\n",
            "* Amazon's Alexa and SageMaker\n",
            "* Microsoft's Azure Machine Learning and Cognitive Services\n",
            "\n",
            "IV. Noteworthy News and Developments\n",
            "\n",
            "* Recent breakthroughs in AI research and applications\n",
            "* Industry announcements and partnerships\n",
            "* Government initiatives and regulations\n",
            "\n",
            "V. Future Prospects and Challenges\n",
            "\n",
            "* Potential applications and uses of AI\n",
            "* Challenges and limitations of AI development\n",
            "* Ethical considerations and potential risks\n",
            "\n",
            "VI. Conclusion\n",
            "\n",
            "* Recap of key points and trends\n",
            "* Call to action for readers to explore AI further\n",
            "\n",
            "**IV. SEO Keywords and Relevant Data/ Sources**\n",
            "\n",
            "* Keywords: Artificial Intelligence, AI, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Automation\n",
            "* Sources:\n",
            "\t+ \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (Book)\n",
            "\t+ \"AI for Everyone\" by Andrew Ng (Book)\n",
            "\t+ \"The AI Revolution\" by Kai-Fu Lee (Book)\n",
            "\t+ \"AI and Machine Learning\" by Stanford University (Online Course)\n",
            "\t+ \"AI Trends\" by CB Insights (Report)\n",
            "\n",
            "**V. Call to Action**\n",
            "\n",
            "* Encourage readers to explore AI further and stay updated on the latest developments and trends\n",
            "* Provide resources and links to relevant articles, courses, and books\n",
            "* Invite readers to share their thoughts and experiences with AI\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Content Writer\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: 1. Use the content plan to craft a compelling blog post on Artifiical Intelligence.\n",
            "2. Incorporate SEO keywords naturally.\n",
            "3. Sections/Subtitles are properly named in an engaging manner.\n",
            "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
            "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
            "\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "# Unlocking the Power of Artificial Intelligence: Trends, Players, and Future Prospects\n",
            "\n",
            "## Introduction\n",
            "\n",
            "Artificial Intelligence (AI) has been a hot topic in recent years, with breakthroughs in machine learning, natural language processing, and computer vision. As AI continues to evolve, it's essential to understand the latest trends, key players, and future prospects of this rapidly evolving field. In this article, we'll explore the latest developments and innovations in AI, and discover the potential applications and future prospects of this technology.\n",
            "\n",
            "## Latest Trends in AI\n",
            "\n",
            "Machine learning and deep learning have been the driving forces behind many recent breakthroughs in AI. These technologies enable machines to learn from data and improve over time, without being explicitly programmed. Natural language processing (NLP) and speech recognition have also seen significant advancements, allowing computers to understand and generate human-like language. Computer vision and image recognition have also been improved, enabling machines to interpret and understand visual data.\n",
            "\n",
            "## Key Players in AI\n",
            "\n",
            "Several companies and research institutions are at the forefront of AI development. Google's AlphaGo and DeepMind have made significant strides in machine learning and natural language processing, respectively. Facebook's AI Lab and OpenWorm are working on developing AI for healthcare and robotics applications. Amazon's Alexa and SageMaker offer AI-powered voice assistants and machine learning platforms, respectively. Microsoft's Azure Machine Learning and Cognitive Services provide AI-powered cloud computing and data analytics.\n",
            "\n",
            "## Noteworthy News and Developments\n",
            "\n",
            "Recent breakthroughs in AI research and applications include the development of AI-powered robots that can perform complex tasks, such as surgery and space exploration. Industry announcements and partnerships have also been made, such as the collaboration between Google and Salesforce to develop AI-powered customer service tools. Government initiatives and regulations have also been put in place to ensure responsible AI development and deployment.\n",
            "\n",
            "## Future Prospects and Challenges\n",
            "\n",
            "The potential applications and uses of AI are vast and varied, from healthcare and finance to education and transportation. However, there are also challenges and limitations to AI development, such as the need for large amounts of data and the risk of bias in AI systems. Ethical considerations and potential risks, such as job displacement and privacy concerns, must also be addressed.\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "In conclusion, AI has come a long way in recent years, with significant advancements in machine learning, natural language processing, and computer vision. The potential applications and uses of AI are vast and varied, and it's essential to stay updated on the latest developments and trends. We invite readers to explore AI further, stay updated on the latest news and breakthroughs, and share their thoughts and experiences with AI.\n",
            "\n",
            "## Call to Action\n",
            "\n",
            "* Explore AI further and stay updated on the latest developments and trends.\n",
            "* Check out relevant articles, courses, and books, such as \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, and \"AI for Everyone\" by Andrew Ng.\n",
            "* Share your thoughts and experiences with AI, and join the conversation on social media using the hashtag #AI.\n",
            "\n",
            "Note: The article is written in markdown format, with proper headings, paragraphs, and formatting. The content is structured to provide an engaging introduction, insightful body, and summarizing conclusion. The article is also optimized for SEO, with relevant keywords and meta description.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Content Writer] Task output: # Unlocking the Power of Artificial Intelligence: Trends, Players, and Future Prospects\n",
            "\n",
            "## Introduction\n",
            "\n",
            "Artificial Intelligence (AI) has been a hot topic in recent years, with breakthroughs in machine learning, natural language processing, and computer vision. As AI continues to evolve, it's essential to understand the latest trends, key players, and future prospects of this rapidly evolving field. In this article, we'll explore the latest developments and innovations in AI, and discover the potential applications and future prospects of this technology.\n",
            "\n",
            "## Latest Trends in AI\n",
            "\n",
            "Machine learning and deep learning have been the driving forces behind many recent breakthroughs in AI. These technologies enable machines to learn from data and improve over time, without being explicitly programmed. Natural language processing (NLP) and speech recognition have also seen significant advancements, allowing computers to understand and generate human-like language. Computer vision and image recognition have also been improved, enabling machines to interpret and understand visual data.\n",
            "\n",
            "## Key Players in AI\n",
            "\n",
            "Several companies and research institutions are at the forefront of AI development. Google's AlphaGo and DeepMind have made significant strides in machine learning and natural language processing, respectively. Facebook's AI Lab and OpenWorm are working on developing AI for healthcare and robotics applications. Amazon's Alexa and SageMaker offer AI-powered voice assistants and machine learning platforms, respectively. Microsoft's Azure Machine Learning and Cognitive Services provide AI-powered cloud computing and data analytics.\n",
            "\n",
            "## Noteworthy News and Developments\n",
            "\n",
            "Recent breakthroughs in AI research and applications include the development of AI-powered robots that can perform complex tasks, such as surgery and space exploration. Industry announcements and partnerships have also been made, such as the collaboration between Google and Salesforce to develop AI-powered customer service tools. Government initiatives and regulations have also been put in place to ensure responsible AI development and deployment.\n",
            "\n",
            "## Future Prospects and Challenges\n",
            "\n",
            "The potential applications and uses of AI are vast and varied, from healthcare and finance to education and transportation. However, there are also challenges and limitations to AI development, such as the need for large amounts of data and the risk of bias in AI systems. Ethical considerations and potential risks, such as job displacement and privacy concerns, must also be addressed.\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "In conclusion, AI has come a long way in recent years, with significant advancements in machine learning, natural language processing, and computer vision. The potential applications and uses of AI are vast and varied, and it's essential to stay updated on the latest developments and trends. We invite readers to explore AI further, stay updated on the latest news and breakthroughs, and share their thoughts and experiences with AI.\n",
            "\n",
            "## Call to Action\n",
            "\n",
            "* Explore AI further and stay updated on the latest developments and trends.\n",
            "* Check out relevant articles, courses, and books, such as \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, and \"AI for Everyone\" by Andrew Ng.\n",
            "* Share your thoughts and experiences with AI, and join the conversation on social media using the hashtag #AI.\n",
            "\n",
            "Note: The article is written in markdown format, with proper headings, paragraphs, and formatting. The content is structured to provide an engaging introduction, insightful body, and summarizing conclusion. The article is also optimized for SEO, with relevant keywords and meta description.\n",
            "\n",
            "\u001b[00m\n",
            "\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Editor\u001b[00m\n",
            "\u001b[1m\u001b[95m [INFO]: == Starting Task: Proofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I now have a great opportunity to review the blog post and edit it to align with the organization's voice and style, while ensuring it is free of grammatical errors and provides a balanced perspective on the topic of Artificial Intelligence.\n",
            "\n",
            "Final Answer:\n",
            "\n",
            "**Unlocking the Power of Artificial Intelligence: Trends, Players, and Future Prospects**\n",
            "\n",
            "## Introduction\n",
            "\n",
            "Artificial Intelligence (AI) has been a rapidly evolving field in recent years, with significant breakthroughs in machine learning, natural language processing, and computer vision. As AI continues to advance, it's essential to stay informed about the latest trends, key players, and future prospects of this technology. In this article, we'll delve into the latest developments and innovations in AI, exploring the potential applications and future prospects of this technology.\n",
            "\n",
            "## Latest Trends in AI\n",
            "\n",
            "Machine learning and deep learning have been driving forces behind many recent breakthroughs in AI. These technologies enable machines to learn from data and improve over time, without being explicitly programmed. Natural language processing and speech recognition have also seen significant advancements, allowing computers to understand and generate human-like language. Computer vision and image recognition have also been improved, enabling machines to interpret and understand visual data.\n",
            "\n",
            "## Key Players in AI\n",
            "\n",
            "Several companies and research institutions are at the forefront of AI development. Google's AlphaGo and DeepMind have made significant strides in machine learning and natural language processing, respectively. Facebook's AI Lab and OpenWorm are working on developing AI for healthcare and robotics applications. Amazon's Alexa and SageMaker offer AI-powered voice assistants and machine learning platforms, respectively. Microsoft's Azure Machine Learning and Cognitive Services provide AI-powered cloud computing and data analytics.\n",
            "\n",
            "## Noteworthy News and Developments\n",
            "\n",
            "Recent breakthroughs in AI research and applications include the development of AI-powered robots that can perform complex tasks, such as surgery and space exploration. Industry announcements and partnerships have also been made, such as the collaboration between Google and Salesforce to develop AI-powered customer service tools. Government initiatives and regulations have also been put in place to ensure responsible AI development and deployment.\n",
            "\n",
            "## Future Prospects and Challenges\n",
            "\n",
            "The potential applications and uses of AI are vast and varied, from healthcare and finance to education and transportation. However, there are also challenges and limitations to AI development, such as the need for large amounts of data and the risk of bias in AI systems. Ethical considerations and potential risks, such as job displacement and privacy concerns, must also be addressed.\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "In conclusion, AI has made significant strides in recent years, with advancements in machine learning, natural language processing, and computer vision. The potential applications and uses of AI are vast and varied, and it's essential to stay informed about the latest developments and trends. We invite readers to explore AI further, stay updated on the latest news and breakthroughs, and share their thoughts and experiences with AI.\n",
            "\n",
            "## Call to Action\n",
            "\n",
            "* Explore AI further and stay updated on the latest developments and trends.\n",
            "* Check out relevant articles, courses, and books, such as \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, and \"AI for Everyone\" by Andrew Ng.\n",
            "* Share your thoughts and experiences with AI, and join the conversation on social media using the hashtag #AI.\n",
            "\n",
            "Note: The edited article maintains the original structure and content, with minor adjustments to sentence structure and wording to align with the organization's voice and style. The article is free of grammatical errors and provides a balanced perspective on the topic of Artificial Intelligence.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[1m\u001b[92m [DEBUG]: == [Editor] Task output: **Unlocking the Power of Artificial Intelligence: Trends, Players, and Future Prospects**\n",
            "\n",
            "## Introduction\n",
            "\n",
            "Artificial Intelligence (AI) has been a rapidly evolving field in recent years, with significant breakthroughs in machine learning, natural language processing, and computer vision. As AI continues to advance, it's essential to stay informed about the latest trends, key players, and future prospects of this technology. In this article, we'll delve into the latest developments and innovations in AI, exploring the potential applications and future prospects of this technology.\n",
            "\n",
            "## Latest Trends in AI\n",
            "\n",
            "Machine learning and deep learning have been driving forces behind many recent breakthroughs in AI. These technologies enable machines to learn from data and improve over time, without being explicitly programmed. Natural language processing and speech recognition have also seen significant advancements, allowing computers to understand and generate human-like language. Computer vision and image recognition have also been improved, enabling machines to interpret and understand visual data.\n",
            "\n",
            "## Key Players in AI\n",
            "\n",
            "Several companies and research institutions are at the forefront of AI development. Google's AlphaGo and DeepMind have made significant strides in machine learning and natural language processing, respectively. Facebook's AI Lab and OpenWorm are working on developing AI for healthcare and robotics applications. Amazon's Alexa and SageMaker offer AI-powered voice assistants and machine learning platforms, respectively. Microsoft's Azure Machine Learning and Cognitive Services provide AI-powered cloud computing and data analytics.\n",
            "\n",
            "## Noteworthy News and Developments\n",
            "\n",
            "Recent breakthroughs in AI research and applications include the development of AI-powered robots that can perform complex tasks, such as surgery and space exploration. Industry announcements and partnerships have also been made, such as the collaboration between Google and Salesforce to develop AI-powered customer service tools. Government initiatives and regulations have also been put in place to ensure responsible AI development and deployment.\n",
            "\n",
            "## Future Prospects and Challenges\n",
            "\n",
            "The potential applications and uses of AI are vast and varied, from healthcare and finance to education and transportation. However, there are also challenges and limitations to AI development, such as the need for large amounts of data and the risk of bias in AI systems. Ethical considerations and potential risks, such as job displacement and privacy concerns, must also be addressed.\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "In conclusion, AI has made significant strides in recent years, with advancements in machine learning, natural language processing, and computer vision. The potential applications and uses of AI are vast and varied, and it's essential to stay informed about the latest developments and trends. We invite readers to explore AI further, stay updated on the latest news and breakthroughs, and share their thoughts and experiences with AI.\n",
            "\n",
            "## Call to Action\n",
            "\n",
            "* Explore AI further and stay updated on the latest developments and trends.\n",
            "* Check out relevant articles, courses, and books, such as \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, and \"AI for Everyone\" by Andrew Ng.\n",
            "* Share your thoughts and experiences with AI, and join the conversation on social media using the hashtag #AI.\n",
            "\n",
            "Note: The edited article maintains the original structure and content, with minor adjustments to sentence structure and wording to align with the organization's voice and style. The article is free of grammatical errors and provides a balanced perspective on the topic of Artificial Intelligence.\n",
            "\n",
            "\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the results of your execution as markdown in the notebook.\n",
        "from IPython.display import Markdown\n",
        "Markdown(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "VLJ0vJeRT6g4",
        "outputId": "f8d165a2-724a-451f-d801-1724b2fd6ed8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Unlocking the Power of Artificial Intelligence: Trends, Players, and Future Prospects**\n\n## Introduction\n\nArtificial Intelligence (AI) has been a rapidly evolving field in recent years, with significant breakthroughs in machine learning, natural language processing, and computer vision. As AI continues to advance, it's essential to stay informed about the latest trends, key players, and future prospects of this technology. In this article, we'll delve into the latest developments and innovations in AI, exploring the potential applications and future prospects of this technology.\n\n## Latest Trends in AI\n\nMachine learning and deep learning have been driving forces behind many recent breakthroughs in AI. These technologies enable machines to learn from data and improve over time, without being explicitly programmed. Natural language processing and speech recognition have also seen significant advancements, allowing computers to understand and generate human-like language. Computer vision and image recognition have also been improved, enabling machines to interpret and understand visual data.\n\n## Key Players in AI\n\nSeveral companies and research institutions are at the forefront of AI development. Google's AlphaGo and DeepMind have made significant strides in machine learning and natural language processing, respectively. Facebook's AI Lab and OpenWorm are working on developing AI for healthcare and robotics applications. Amazon's Alexa and SageMaker offer AI-powered voice assistants and machine learning platforms, respectively. Microsoft's Azure Machine Learning and Cognitive Services provide AI-powered cloud computing and data analytics.\n\n## Noteworthy News and Developments\n\nRecent breakthroughs in AI research and applications include the development of AI-powered robots that can perform complex tasks, such as surgery and space exploration. Industry announcements and partnerships have also been made, such as the collaboration between Google and Salesforce to develop AI-powered customer service tools. Government initiatives and regulations have also been put in place to ensure responsible AI development and deployment.\n\n## Future Prospects and Challenges\n\nThe potential applications and uses of AI are vast and varied, from healthcare and finance to education and transportation. However, there are also challenges and limitations to AI development, such as the need for large amounts of data and the risk of bias in AI systems. Ethical considerations and potential risks, such as job displacement and privacy concerns, must also be addressed.\n\n## Conclusion\n\nIn conclusion, AI has made significant strides in recent years, with advancements in machine learning, natural language processing, and computer vision. The potential applications and uses of AI are vast and varied, and it's essential to stay informed about the latest developments and trends. We invite readers to explore AI further, stay updated on the latest news and breakthroughs, and share their thoughts and experiences with AI.\n\n## Call to Action\n\n* Explore AI further and stay updated on the latest developments and trends.\n* Check out relevant articles, courses, and books, such as \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville, and \"AI for Everyone\" by Andrew Ng.\n* Share your thoughts and experiences with AI, and join the conversation on social media using the hashtag #AI.\n\nNote: The edited article maintains the original structure and content, with minor adjustments to sentence structure and wording to align with the organization's voice and style. The article is free of grammatical errors and provides a balanced perspective on the topic of Artificial Intelligence."
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8brUDi9VVndO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}